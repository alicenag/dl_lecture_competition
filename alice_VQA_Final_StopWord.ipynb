{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXJIEQN1U1gu"
      },
      "source": [
        "# いろんな準備"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WandBを準備\n",
        "# インストール\n",
        "!pip install wandb -qU\n",
        "import wandb\n",
        "from google.colab import userdata\n",
        "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
        "# Login\n",
        "!wandb login $wandb_api_key"
      ],
      "metadata": {
        "id": "11CLnW7Ye6ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNAAULC30rDA"
      },
      "outputs": [],
      "source": [
        "# Gドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ディレクトリを準備\n",
        "!mkdir -p data\n",
        "drive_path = \"/content/drive/MyDrive/Colab Notebooks/DLBasics2023_colab/final-vqa\"\n",
        "data_path = f\"{drive_path}/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5bdoX-NDxGx"
      },
      "outputs": [],
      "source": [
        "# 学習データの読み込み\n",
        "!rsync -ah --no-i-r --info=progress2 \"{data_path}/train.json\" \"./data/\"\n",
        "!rsync -ah --no-i-r --info=progress2 \"{data_path}/valid.json\" \"./data/\"\n",
        "!rsync -ah --no-i-r --info=progress2 \"{data_path}/train.zip\" \"./data/\"\n",
        "!rsync -ah --no-i-r --info=progress2 \"{data_path}/valid.zip\" \"./data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データを解凍\n",
        "!apt install -y -qq parallel > /dev/null\n",
        "\n",
        "%cd /content/data\n",
        "!zipinfo -1 train.zip | parallel --no-notice --bar \"unzip -qn train.zip {}\"\n",
        "!zipinfo -1 valid.zip | parallel --no-notice --bar \"unzip -qn valid.zip {}\""
      ],
      "metadata": {
        "id": "R3AHJY9Rn9v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDwnTNEdU_Af"
      },
      "source": [
        "## ここからがベースライン\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLYemIsiyWIM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import time\n",
        "import datetime as dt\n",
        "\n",
        "from statistics import mode\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXo11IfNyZ6k"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 工夫：高速化\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "3sGoNQY3QnQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 質問文の前処理１（工夫：うまく行かなかった）\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def stemming(question):\n",
        "    stemmer = PorterStemmer()\n",
        "    return ' '.join([stemmer.stem(word) for word in question.split()])"
      ],
      "metadata": {
        "id": "5rfdrTy9lN7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 質問文の前処理２（工夫：OK）\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def remove_stopwords(question):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return ' '.join([word for word in question.split() if word not in stop_words])"
      ],
      "metadata": {
        "id": "Rco2r-t1jbnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG6qxiqBxuQ4"
      },
      "outputs": [],
      "source": [
        "def process_text(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 数詞を数字に変換\n",
        "    num_word_to_digit = {\n",
        "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
        "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
        "        'ten': '10'\n",
        "    }\n",
        "    for word, digit in num_word_to_digit.items():\n",
        "        text = text.replace(word, digit)\n",
        "\n",
        "    # 小数点のピリオドを削除\n",
        "    text = re.sub(r'(?<!\\d)\\.(?!\\d)', '', text)\n",
        "\n",
        "    # 冠詞の削除\n",
        "    text = re.sub(r'\\b(a|an|the)\\b', '', text)\n",
        "\n",
        "    # 短縮形のカンマの追加\n",
        "    contractions = {\n",
        "        \"dont\": \"don't\", \"isnt\": \"isn't\", \"arent\": \"aren't\", \"wont\": \"won't\",\n",
        "        \"cant\": \"can't\", \"wouldnt\": \"wouldn't\", \"couldnt\": \"couldn't\"\n",
        "    }\n",
        "    for contraction, correct in contractions.items():\n",
        "        text = text.replace(contraction, correct)\n",
        "\n",
        "    # 句読点をスペースに変換\n",
        "    text = re.sub(r\"[^\\w\\s':]\", ' ', text)\n",
        "\n",
        "    # 句読点をスペースに変換\n",
        "    text = re.sub(r'\\s+,', ',', text)\n",
        "\n",
        "    # 連続するスペースを1つに変換\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "\n",
        "    # 質問文の前処理：工夫\n",
        "    text = remove_stopwords(text)\n",
        "    # text = stemming(text)  # うまく動かなかった\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPHhTZxAyT3i"
      },
      "outputs": [],
      "source": [
        "# データローダーの作成\n",
        "class VQADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df_path, image_dir, transform=None, answer=True):\n",
        "        self.transform = transform  # 画像の前処理\n",
        "        self.image_dir = image_dir  # 画像ファイルのディレクトリ\n",
        "        self.df = pd.read_json(df_path)  # 画像ファイルのパス，question, answerを持つDataFrame\n",
        "        self.answer = answer\n",
        "\n",
        "        # question / answerの辞書を作成\n",
        "        self.question2idx = {}\n",
        "        self.answer2idx = {}\n",
        "        self.idx2question = {}\n",
        "        self.idx2answer = {}\n",
        "\n",
        "        # 質問文に含まれる単語を辞書に追加\n",
        "        for question in self.df[\"question\"]:\n",
        "            question = process_text(question)\n",
        "            words = question.split(\" \")\n",
        "            for word in words:\n",
        "                if word not in self.question2idx:\n",
        "                    self.question2idx[word] = len(self.question2idx)\n",
        "        self.idx2question = {v: k for k, v in self.question2idx.items()}  # 逆変換用の辞書(question)\n",
        "\n",
        "        if self.answer:\n",
        "            # 回答に含まれる単語を辞書に追加\n",
        "            for answers in self.df[\"answers\"]:\n",
        "                for answer in answers:\n",
        "                    word = answer[\"answer\"]\n",
        "                    word = process_text(word)\n",
        "                    if word not in self.answer2idx:\n",
        "                        self.answer2idx[word] = len(self.answer2idx)\n",
        "            self.idx2answer = {v: k for k, v in self.answer2idx.items()}  # 逆変換用の辞書(answer)\n",
        "\n",
        "    def update_dict(self, dataset):\n",
        "        \"\"\"\n",
        "        検証用データ，テストデータの辞書を訓練データの辞書に更新する．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset : Dataset\n",
        "            訓練データのDataset\n",
        "        \"\"\"\n",
        "        self.question2idx = dataset.question2idx\n",
        "        self.answer2idx = dataset.answer2idx\n",
        "        self.idx2question = dataset.idx2question\n",
        "        self.idx2answer = dataset.idx2answer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        対応するidxのデータ（画像，質問，回答）を取得．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        idx : int\n",
        "            取得するデータのインデックス\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        image : torch.Tensor  (C, H, W)\n",
        "            画像データ\n",
        "        question : torch.Tensor  (vocab_size)\n",
        "            質問文をone-hot表現に変換したもの\n",
        "        answers : torch.Tensor  (n_answer)\n",
        "            10人の回答者の回答のid\n",
        "        mode_answer_idx : torch.Tensor  (1)\n",
        "            10人の回答者の回答の中で最頻値の回答のid\n",
        "        \"\"\"\n",
        "        image = Image.open(f\"{self.image_dir}/{self.df['image'][idx]}\")\n",
        "        image = self.transform(image)\n",
        "        question = np.zeros(len(self.idx2question) + 1)  # 未知語用の要素を追加\n",
        "        question_words = self.df[\"question\"][idx].split(\" \")\n",
        "        for word in question_words:\n",
        "            try:\n",
        "                question[self.question2idx[word]] = 1  # one-hot表現に変換\n",
        "            except KeyError:\n",
        "                question[-1] = 1  # 未知語\n",
        "\n",
        "\n",
        "        if self.answer:\n",
        "            answers = [self.answer2idx[process_text(answer[\"answer\"])] for answer in self.df[\"answers\"][idx]]\n",
        "            mode_answer_idx = mode(answers)  # 最頻値を取得（正解ラベル）\n",
        "\n",
        "            return image, torch.Tensor(question), torch.Tensor(answers), int(mode_answer_idx)\n",
        "\n",
        "        else:\n",
        "            return image, torch.Tensor(question)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyGnqGFmyQ6E"
      },
      "outputs": [],
      "source": [
        "# 2. 評価指標の実装\n",
        "# 簡単にするならBCEを利用する\n",
        "def VQA_criterion(batch_pred: torch.Tensor, batch_answers: torch.Tensor):\n",
        "    total_acc = 0.\n",
        "\n",
        "    for pred, answers in zip(batch_pred, batch_answers):\n",
        "        acc = 0.\n",
        "        for i in range(len(answers)):\n",
        "            num_match = 0\n",
        "            for j in range(len(answers)):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                if pred == answers[j]:\n",
        "                    num_match += 1\n",
        "            acc += min(num_match / 3, 1)\n",
        "        total_acc += acc / 10\n",
        "\n",
        "    return total_acc / len(batch_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuJr8h7xyJM9"
      },
      "outputs": [],
      "source": [
        "# 3. モデルの実装\n",
        "# ResNetを利用できるようにしておく\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X55AJ-xOyG0w"
      },
      "outputs": [],
      "source": [
        "class BottleneckBlock(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMG_exffyEHr"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, layers[0], 64)\n",
        "        self.layer2 = self._make_layer(block, layers[1], 128, stride=2)\n",
        "        self.layer3 = self._make_layer(block, layers[2], 256, stride=2)\n",
        "        self.layer4 = self._make_layer(block, layers[3], 512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, 512)\n",
        "\n",
        "    def _make_layer(self, block, blocks, out_channels, stride=1):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(BottleneckBlock, [3, 4, 6, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp9L8UQByASM"
      },
      "outputs": [],
      "source": [
        "class VQAModel(nn.Module):\n",
        "    def __init__(self, vocab_size: int, n_answer: int):\n",
        "        super().__init__()\n",
        "        self.resnet = ResNet18()\n",
        "        self.text_encoder = nn.Linear(vocab_size, 512)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, n_answer)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, question):\n",
        "        image_feature = self.resnet(image)              # 画像の特徴量\n",
        "        question_feature = self.text_encoder(question)  # テキストの特徴量\n",
        "\n",
        "        x = torch.cat([image_feature, question_feature], dim=1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfpKP4yqx8_W"
      },
      "outputs": [],
      "source": [
        "# 4. 学習の実装\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model = model.to(device, non_blocking=True)\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    simple_acc = 0\n",
        "\n",
        "    start = time.time()\n",
        "    for image, question, answers, mode_answer in dataloader:\n",
        "        image = image.to(device, non_blocking=True)\n",
        "        question = question.to(device, non_blocking=True)\n",
        "        answers = answers.to(device, non_blocking=True)\n",
        "        mode_answer = mode_answer.to(device, non_blocking=True)\n",
        "\n",
        "        pred = model(image, question)\n",
        "        loss = criterion(pred, mode_answer.squeeze())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += VQA_criterion(pred.argmax(1), answers)    # VQA accuracy\n",
        "        simple_acc += (pred.argmax(1) == mode_answer).float().mean().item()  # simple accuracy\n",
        "\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader), simple_acc / len(dataloader), time.time() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yuu2nWwBx8BU"
      },
      "outputs": [],
      "source": [
        "# 評価関数\n",
        "def eval(model, dataloader, optimizer, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    simple_acc = 0\n",
        "\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "      for image, question, answers, mode_answer in dataloader:\n",
        "          image = image.to(device, non_blocking=True)\n",
        "          question = question.to(device, non_blocking=True)\n",
        "          answers = answers.to(device, non_blocking=True)\n",
        "          mode_answer = mode_answer.to(device, non_blocking=True)\n",
        "\n",
        "          pred = model(image, question)\n",
        "          loss = criterion(pred, mode_answer.squeeze())\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          total_acc += VQA_criterion(pred.argmax(1), answers)   # VQA accuracy\n",
        "          simple_acc += (pred.argmax(1) == mode_answer).float().mean().item()  # simple accuracy\n",
        "\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader), simple_acc / len(dataloader), time.time() - start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 便利なツール"
      ],
      "metadata": {
        "id": "IIjy92HNM_pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB Tool\n",
        "def start_wandb():\n",
        "    wandb.init()\n",
        "    return  wandb.config\n",
        "\n",
        "\n",
        "def epoch_log(epoch, train_loss, train_acc, train_simple_acc, train_time, valid_loss, valid_acc, valid_simple_acc, valid_time):\n",
        "    # wandbへ出力\n",
        "    wandb.log({\n",
        "      \"train_time\": train_time,\n",
        "      \"train_loss\": train_loss,\n",
        "      \"train_acc\": train_acc,\n",
        "      \"train_simple-acc\": train_simple_acc,\n",
        "      \"valid_time\": valid_time,\n",
        "      \"valid_loss\": valid_loss,\n",
        "      \"valid_acc\": valid_acc,\n",
        "      \"valid_simple_acc-acc\": valid_simple_acc,\n",
        "      \"epoch\": epoch\n",
        "    })\n",
        "\n",
        "    # セルへ出力\n",
        "    print(f\"【{epoch}】\\n\"\n",
        "      f\"t-time: {train_time:.2f} [s]\\n\"\n",
        "      f\"t-loss: {train_loss:.4f}\\n\"\n",
        "      f\"t-acc: {train_acc:.4f}\\n\"\n",
        "      f\"t-simple-acc: {train_simple_acc:.4f}\\n\"\n",
        "      f\"v-time: {valid_time:.2f} [s]\\n\"\n",
        "      f\"v-loss: {valid_loss:.4f}\\n\"\n",
        "      f\"v-acc: {valid_acc:.4f}\\n\"\n",
        "      f\"v-simple-acc: {valid_simple_acc:.4f}\\n\"\n",
        "    )"
      ],
      "metadata": {
        "id": "BQ-rrlQA7Oc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping クラス\n",
        "class EarlyStopping:\n",
        "    def __init__(self, mode='loss', patience=10, delta=0, path='checkpoint.pth'):\n",
        "        self.mode = mode\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "        self.early_stop = False\n",
        "\n",
        "        self.counter = 0\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.val_acc_max = 0\n",
        "        self.best_epoch = None\n",
        "\n",
        "    def __call__(self, epoch_no, val_loss, val_acc, model, optimizer):\n",
        "        # Update By Minimun Loss\n",
        "        if self.mode == 'loss' :\n",
        "            if val_loss <= self.val_loss_min :\n",
        "                self.val_loss_min = val_loss\n",
        "                self.val_acc_max = val_acc\n",
        "                self.best_epoch = epoch_no\n",
        "                self.save_checkpoint(epoch_no, val_loss, val_acc, model, optimizer)\n",
        "\n",
        "                self.counter = 0\n",
        "\n",
        "            else: # case: val_loss > self.val_loss_min\n",
        "                if val_loss > self.val_loss_min + self.delta :\n",
        "                    self.counter += 1\n",
        "                    if self.counter >= self.patience:\n",
        "                        self.early_stop = True\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "        # Update By Max Accuracy\n",
        "        else: # self.mode == \"acc\"\n",
        "            if val_acc >= self.val_acc_max :\n",
        "                self.val_acc_max = val_acc\n",
        "                self.val_loss_min = val_loss\n",
        "                self.best_epoch = epoch_no\n",
        "                self.save_checkpoint(epoch_no, val_loss, val_acc, model, optimizer)\n",
        "\n",
        "                self.counter = 0\n",
        "\n",
        "            else: # case: val_acc < self.val_acc_max\n",
        "                if val_acc < self.val_acc_max - self.delta :\n",
        "                    self.counter += 1\n",
        "                    if self.counter >= self.patience:\n",
        "                        self.early_stop = True\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def save_checkpoint(self, epoch_no, val_loss, val_acc, model, optimizer):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        torch.save({\n",
        "            'epoch_no': epoch_no,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "            'model_state_dict': model.cpu().state_dict(),   # [Attension!] Move model to CPU\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, self.path)"
      ],
      "metadata": {
        "id": "i5Yj1nmGNmyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA5rz7J-zzZS"
      },
      "source": [
        "# 学習開始"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deviceの設定\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "zhjV-VmO9f7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStop Parameters\n",
        "earlystop_patience = 5\n",
        "earlystop_threshold = 0.1\n",
        "tmp_best_model_filename = \"temporary_best_model.pth\"\n",
        "\n",
        "def build_earlystopping():\n",
        "    # EarlyStoppingのインスタンス\n",
        "    early_stopping = EarlyStopping(\n",
        "                        mode='acc',\n",
        "                        patience=earlystop_patience,\n",
        "                        delta=earlystop_threshold,\n",
        "                        path=tmp_best_model_filename\n",
        "                      )\n",
        "\n",
        "    return early_stopping"
      ],
      "metadata": {
        "id": "a8AGmMfa-k_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データを準備\n"
      ],
      "metadata": {
        "id": "dW2mpn-uMiuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZWzK3D7zOqM"
      },
      "outputs": [],
      "source": [
        "def build_datasets(split_ratio = 0.8):\n",
        "\n",
        "    # ----------------------\n",
        "    # 画像変換ロジックtransformを設定\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # ----------------------\n",
        "    # データセットの取り出し（学習用）\n",
        "    train_val_dataset = VQADataset(df_path=\"./data/train.json\", image_dir=\"./data/train\", transform=transform)\n",
        "\n",
        "    # データセットの長さを取得\n",
        "    train_val_dataset_size = len(train_val_dataset)\n",
        "\n",
        "    # トレーニングセットとテストセットのサイズ\n",
        "    train_size = int(split_ratio * train_val_dataset_size)\n",
        "    valid_size = train_val_dataset_size - train_size\n",
        "\n",
        "    # トレーニングセットとテストセットに分割\n",
        "    train_dataset, valid_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, valid_size])\n",
        "\n",
        "    # 辞書をサブセットにコピー\n",
        "    train_dataset.question2idx = train_val_dataset.question2idx\n",
        "    train_dataset.answer2idx = train_val_dataset.answer2idx\n",
        "    train_dataset.idx2question = train_val_dataset.idx2question\n",
        "    train_dataset.idx2answer = train_val_dataset.idx2answer\n",
        "\n",
        "    # 辞書をサブセットにコピー\n",
        "    valid_dataset.question2idx = train_val_dataset.question2idx\n",
        "    valid_dataset.answer2idx = train_val_dataset.answer2idx\n",
        "    valid_dataset.idx2question = train_val_dataset.idx2question\n",
        "    valid_dataset.idx2answer = train_val_dataset.idx2answer\n",
        "\n",
        "    # ----------------------\n",
        "    # データセットの取り出し（提出用）\n",
        "    test_dataset = VQADataset(df_path=\"./data/valid.json\", image_dir=\"./data/valid\", transform=transform, answer=False)\n",
        "    test_dataset.update_dict(train_val_dataset)\n",
        "\n",
        "    return train_dataset, valid_dataset, test_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーの作成\n",
        "def get_dataloader(train_dataset, valid_dataset, test_dataset, batch_size, num_workers=4):\n",
        "    \"\"\"\n",
        "      --- 高速化フラグ  num_workers=4, pin_memory=True, pin_memory_device=device ---\n",
        "    \"\"\"\n",
        "    # 学習・検証用のデータローダ\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, pin_memory_device=device)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, pin_memory_device=device)\n",
        "\n",
        "    # 提出結果作成用のデータローダ\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=num_workers, pin_memory=True, pin_memory_device=device)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n"
      ],
      "metadata": {
        "id": "Rm60J_U90lkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# モデルを準備"
      ],
      "metadata": {
        "id": "wBnM57SoN0eh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nrvCa4lzSge"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "def build_model(vocab_size, n_answer):\n",
        "    model = VQAModel( vocab_size=vocab_size, n_answer = n_answer).to(device, non_blocking=True)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I8b0Fo3KmVIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# 学習"
      ],
      "metadata": {
        "id": "5ZKUTfARN1Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wandbの設定(Sweepsの実行)\n",
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "        'name': 'valid_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            # 'values': [1, 3, 5]\n",
        "            'values': [5]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            # 'values': [32, 64, 128]\n",
        "            'values': [128]\n",
        "        },\n",
        "        'lr': {\n",
        "            # 'values': [1e-2, 1e-4, 1e-5, 1e-6]\n",
        "            'values': [1e-4]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "H6CuFrhe0OVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グローバル変数の準備\n",
        "model = None\n",
        "optimizer = None\n",
        "criterion = None\n",
        "\n",
        "train_dataset = None\n",
        "valid_dataset= None\n",
        "test_dataset = None\n",
        "\n",
        "train_loader = None\n",
        "valid_loader = None\n",
        "test_loader = None"
      ],
      "metadata": {
        "id": "VtUQEx3W_Mo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fnVhAuHzlHB"
      },
      "outputs": [],
      "source": [
        "# 学習関数(for Sweep)\n",
        "\n",
        "def main():\n",
        "\n",
        "    global model, optimizer, criterion, train_dataset, valid_dataset, test_dataset, train_loader, valid_loader, test_loader\n",
        "\n",
        "    # --------------------------\n",
        "    wandb.init()\n",
        "    config = wandb.config\n",
        "    early_stopping = build_earlystopping()\n",
        "\n",
        "    # Dataset and Dataloader\n",
        "    train_dataset, valid_dataset, test_dataset = build_datasets()\n",
        "    train_loader, valid_loader, test_loader = get_dataloader(train_dataset, valid_dataset, test_dataset, config.batch_size)\n",
        "\n",
        "    # Model and optimizer\n",
        "    model = build_model(vocab_size=len(train_dataset.question2idx)+1, n_answer=len(train_dataset.answer2idx))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # --------------------------\n",
        "    # train　loop\n",
        "    for epoch in range(1, config.epochs+1):\n",
        "        # Trainning and Varidatiion\n",
        "        train_loss, train_acc, train_simple_acc, train_time = train(model, train_loader, optimizer, criterion, device)\n",
        "        valid_loss, valid_acc, valid_simple_acc, valid_time = eval(model, valid_loader, optimizer, criterion, device)\n",
        "\n",
        "        # ログ\n",
        "        epoch_log(epoch, train_loss, train_acc, train_simple_acc, train_time, valid_loss, valid_acc, valid_simple_acc, valid_time)\n",
        "\n",
        "        # EarlyStop処理\n",
        "        if early_stopping(epoch, valid_loss, valid_acc, model, optimizer) :\n",
        "          print(f\"======>>>> Early Stopped!!!:   best_valid_acc:{early_stopping.val_acc_max :4f}\")\n",
        "          break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数を固定\n",
        "set_seed(42)\n",
        "# Sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project='vqa-baseline-sweep')\n",
        "\n",
        "##### 学習実行！ ####\n",
        "wandb.agent(sweep_id, function=main, count=1)\n"
      ],
      "metadata": {
        "id": "H5D58QzxyMC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# 結果出力"
      ],
      "metadata": {
        "id": "QZOZfHaEKgn3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K38OXgpGQZ4X"
      },
      "outputs": [],
      "source": [
        "# === ファイル名の生成 ===\n",
        "from google.colab import files\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "# タイムスタンプ文字列を作成\n",
        "utc_now = datetime.datetime.now()\n",
        "jst_now = utc_now.astimezone(pytz.timezone('Asia/Tokyo'))\n",
        "formatted_date = jst_now.strftime(\"%Y-%m-%dT%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unnMEiaJx33O"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# 最終エポック\n",
        "npy_filename = f\"VQA_submission_pred-{formatted_date}-last.npy\"\n",
        "print(npy_filename)\n",
        "\n",
        "# 提出用ファイル\n",
        "model = model.to(device, non_blocking=True)\n",
        "model.eval()\n",
        "submission = []\n",
        "for image, question in test_loader:\n",
        "    image = image.to(device, non_blocking=True)\n",
        "    question = question.to(device, non_blocking=True)\n",
        "    print(f\"question: {question}\")\n",
        "\n",
        "    pred = model(image, question)\n",
        "    pred = pred.argmax(1).cpu().item()\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "\n",
        "    submission.append(pred)\n",
        "\n",
        "submission = [train_dataset.idx2answer[id] for id in submission]\n",
        "submission = np.array(submission)\n",
        "\n",
        "# npyファイルをダウンロード\n",
        "np.save(npy_filename, submission)\n",
        "files.download(npy_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# Best結果を出力"
      ],
      "metadata": {
        "id": "XGpzjCR5EfVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BESTモデルの再ロード\n",
        "checkpoint = torch.load(tmp_best_model_filename, map_location=torch.device('cpu'))\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "val_loss = checkpoint['val_loss']\n",
        "val_acc = checkpoint['val_acc']\n",
        "best_epoch_id = checkpoint['epoch_no']\n",
        "\n",
        "print(f\"best_epoch_id: {best_epoch_id}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}\\n\")"
      ],
      "metadata": {
        "id": "Rmbce-bw7s-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BESTエポックの結果を出力\n",
        "npy_filename = f\"VQA_submission_pred-{formatted_date}-best.npy\"\n",
        "print(npy_filename)\n",
        "\n",
        "# 提出用ファイルの作成\n",
        "model = model.to(device, non_blocking=True)\n",
        "\n",
        "model.eval()\n",
        "submission = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image, question in test_loader:\n",
        "      image = image.to(device, non_blocking=True)\n",
        "      question = question.to(device, non_blocking=True)\n",
        "\n",
        "      pred = model(image, question)\n",
        "      pred = pred.argmax(1).cpu().item()\n",
        "      submission.append(pred)\n",
        "\n",
        "submission = [train_dataset.idx2answer[id] for id in submission]\n",
        "submission = np.array(submission)\n",
        "\n",
        "# ローカルにnpyファイルをダウンロードする\n",
        "np.save(npy_filename, submission)\n",
        "files.download(npy_filename)"
      ],
      "metadata": {
        "id": "ci1r0Z2jIneq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}